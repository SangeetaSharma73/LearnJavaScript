# ğŸš€ Understanding Streams in Node.js

## âœ… Why use streams?

When you read a large file with fs.readFile(), Node tries to load the entire file into memory at once.
That works for small files, but will crash your server if you try it with a huge video or log file.

### ğŸ‘‰ Streams solve this problem by:

- reading data in chunks
- processing data while reading it
- using very little memory

## âœ… How streams work

In Node.js, a stream is like a pipe:

- Data flows through the pipe
- You can read it chunk by chunk
- You can also pause, resume, or pipe it elsewhere (like to a network socket or another file)

## There are four types of streams:

- Readable (e.g. reading a file)
- Writable (e.g. writing to a file)
- Duplex (both read/write)
- Transform (modify data on the fly)

For your assignment, youâ€™ll use a Readable stream to read a large file.

## âœ… Conceptual steps to solve this assignment

### 1ï¸âƒ£ Create a readable stream

- use fs.createReadStream()
- give it a path to a large file
- optionally specify the highWaterMark (chunk size)

### 2ï¸âƒ£ Listen for events on the stream

Streams emit events:

- data â€” fires for each chunk
- end â€” fires when the whole stream is done
- error â€” fires if thereâ€™s a problem

### 3ï¸âƒ£ Track progress

- Each time you get a chunk (data event), measure its size

- Add the chunk size to a running total

- Print out progress in percentage

### 4ï¸âƒ£ On end event

- log â€œreading finishedâ€

- show the total size you read

### âœ… Summary of what youâ€™d do

âœ” Import the fs module
âœ” Create a readable stream from a large file
âœ” Listen for data to get each chunk
âœ” Use .length to measure how much data you got so far
âœ” Listen for end to know when itâ€™s done
âœ” Optionally listen for error

### âœ… Things to remember

- Streams are asynchronous
- They work chunk-by-chunk
- They emit events
- They help handle large data with minimal memory

### ğŸš€ What you should build

ğŸ‘‰ A program that:

```txt
opens a large file with createReadStream()

logs a progress message for every chunk (e.g., â€œRead 20% doneâ€)

finally logs a â€œcompleteâ€ message at the end
```

## ğŸš€ Node.js Stream Example: Reading a large file and showing progress

Imagine you have a large text file called bigfile.txt.
We will read it in chunks, log how much we have read so far, and show progress as a percentage.

### Step-by-Step Explanation

// 1ï¸âƒ£ Load the required module

const fs = require('fs');
ğŸ‘‰ We need Nodeâ€™s fs module to handle file operations.

// 2ï¸âƒ£ Find the file size first so we can calculate percentage
const filePath = 'bigfile.txt';
const stats = fs.statSync(filePath);
const totalSize = stats.size;

ğŸ‘‰fs.statSync synchronously gets file info (like its size in bytes).
totalSize will help us track progress later.

// 3ï¸âƒ£ Create a readable stream from the file
const readStream = fs.createReadStream(filePath);

ğŸ‘‰
This returns a Readable stream.

Node will automatically break the file into chunks (default chunk size is 64 KB).

These chunks will be sent through the stream, event by event.

// 4ï¸âƒ£ Set up variables to track progress
let bytesRead = 0;
ğŸ‘‰ Weâ€™ll accumulate how many bytes we have read so far.

// 5ï¸âƒ£ Listen for 'data' events, which give us each chunk
readStream.on('data', (chunk) => {
bytesRead += chunk.length; // accumulate how many bytes weâ€™ve read so far
const percent = ((bytesRead / totalSize) \* 100).toFixed(2); // calculate percentage
console.log(`Progress: ${percent}%`);
});
ğŸ‘‰
Every time data arrives, this callback fires.

chunk is a Buffer of data

chunk.length tells us its size in bytes

we keep a running total with bytesRead

we calculate the progress as a percentage

// 6ï¸âƒ£ Listen for the 'end' event
readStream.on('end', () => {
console.log('âœ… File reading finished!');
});
ğŸ‘‰
Fires after all chunks have been read

Perfect place to log â€œall doneâ€.

// 7ï¸âƒ£ Listen for any errors
readStream.on('error', (err) => {
console.error('âŒ Error reading file:', err);
});

ğŸ‘‰ Always handle errors with streams â€” e.g. if file is missing.

## âœ… In Plain English

âœ” You open the file with createReadStream
âœ” You listen for chunk events with data
âœ” You add up the chunk sizes to track progress
âœ” You log the percentage
âœ” When finished, the end event fires
